# Sistema RAG Simple para FAQ

Este es un sistema de Retrieval-Augmented Generation (RAG) simple implementado para responder preguntas frecuentes de la clÃ­nica dental.

## ğŸ¯ Â¿QuÃ© es RAG?

RAG combina la bÃºsqueda de informaciÃ³n relevante con la generaciÃ³n de texto de un modelo de lenguaje. En lugar de que el modelo responda solo con su conocimiento general, primero busca informaciÃ³n especÃ­fica en una base de datos y luego genera una respuesta basada en ese contexto.

## ğŸ“ Archivos Creados

1. **`lib/faq-data.ts`** - Base de datos de preguntas frecuentes
2. **`lib/rag-utils.ts`** - Funciones de bÃºsqueda y generaciÃ³n de contexto
3. **`app/api/chat/route.ts`** - API actualizada con capacidad RAG

## ğŸ”§ CÃ³mo Funciona

### 1. Base de Datos FAQ (`faq-data.ts`)

Contiene un array de objetos con:

- `id`: Identificador Ãºnico
- `question`: La pregunta frecuente
- `answer`: La respuesta
- `keywords`: Palabras clave para mejorar la bÃºsqueda

### 2. Sistema de BÃºsqueda (`rag-utils.ts`)

#### `searchFAQs(query, topK)`

Busca las FAQs mÃ¡s relevantes usando:

- **Coincidencia de keywords**: +3 puntos por keyword que coincide
- **Palabras en pregunta**: +2 puntos
- **Palabras en respuesta**: +1 punto
- **Pregunta muy similar**: +5 puntos bonus

Retorna las top K FAQs mÃ¡s relevantes.

#### `generateRAGContext(faqs)`

Genera un prompt estructurado con las FAQs relevantes para que el modelo las use como contexto.

#### `isRelevantForFAQ(query)`

Determina si una consulta es del tipo que podrÃ­a beneficiarse de las FAQs.

### 3. IntegraciÃ³n con Gemini

En la ruta de la API:

1. Si `useFAQ` estÃ¡ activado, extrae la Ãºltima consulta del usuario
2. Verifica si es relevante para FAQs
3. Busca las 3 FAQs mÃ¡s relevantes
4. Genera el contexto RAG
5. Lo incluye en el system prompt de Gemini
6. El modelo responde basÃ¡ndose en ese contexto

## ğŸ¨ Interfaz de Usuario

Se agregÃ³ un botÃ³n **"FAQ"** en la barra de herramientas:

- **Activado** (azul): El chatbot usarÃ¡ la base de conocimiento FAQ
- **Desactivado** (gris): El chatbot responderÃ¡ solo con conocimiento general

## ğŸ“ Agregar Nuevas FAQs

Para agregar nuevas preguntas frecuentes, edita `lib/faq-data.ts`:

```typescript
{
  id: "9",
  question: "Â¿Tu nueva pregunta?",
  answer: "La respuesta detallada...",
  keywords: ["palabra1", "palabra2", "palabra3"]
}
```

**Tips para buenos keywords:**

- Incluye sinÃ³nimos
- Usa verbos y sustantivos clave
- Piensa en cÃ³mo los usuarios preguntarÃ­an
- Incluye tÃ©rminos tÃ©cnicos y coloquiales

## ğŸš€ Mejoras Futuras

### 1. Embeddings Vectoriales

Para bÃºsquedas mÃ¡s precisas, podrÃ­as usar:

```typescript
// Instalar: npm install @google/generative-ai
import { GoogleGenerativeAI } from "@google/generative-ai";

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY);
const model = genAI.getGenerativeModel({ model: "embedding-001" });

// Generar embeddings
const result = await model.embedContent(text);
const embedding = result.embedding;
```

### 2. Base de Datos Vectorial

Usar una DB como:

- **Pinecone** (cloud)
- **Chroma** (local)
- **Supabase pgvector** (ya usas Supabase!)

### 3. Chunking de Documentos

Para documentos largos, dividir en chunks:

```typescript
function chunkDocument(text: string, chunkSize: number = 500) {
  const sentences = text.split(/[.!?]+/);
  const chunks = [];
  let currentChunk = "";

  for (const sentence of sentences) {
    if ((currentChunk + sentence).length < chunkSize) {
      currentChunk += sentence + ". ";
    } else {
      chunks.push(currentChunk.trim());
      currentChunk = sentence + ". ";
    }
  }
  if (currentChunk) chunks.push(currentChunk.trim());
  return chunks;
}
```

### 4. CachÃ© de BÃºsquedas

Implementar cachÃ© para consultas comunes:

```typescript
const searchCache = new Map<string, FAQ[]>();

export function searchFAQsWithCache(query: string, topK: number = 3): FAQ[] {
  const cacheKey = query.toLowerCase();
  if (searchCache.has(cacheKey)) {
    return searchCache.get(cacheKey)!;
  }

  const results = searchFAQs(query, topK);
  searchCache.set(cacheKey, results);
  return results;
}
```

## ğŸ§ª Pruebas

Intenta preguntas como:

- "Â¿CuÃ¡l es el horario?"
- "Â¿CÃ³mo agendo una cita?"
- "Â¿CuÃ¡nto cuesta una limpieza?"
- "Â¿Atienden emergencias?"
- "Â¿Aceptan seguro mÃ©dico?"

Compara las respuestas con y sin el modo FAQ activado.

## ğŸ“Š Ventajas de este Enfoque

âœ… **Simple**: No requiere dependencias adicionales
âœ… **RÃ¡pido**: BÃºsqueda instantÃ¡nea en memoria
âœ… **Controlable**: Sabes exactamente quÃ© informaciÃ³n se usa
âœ… **EconÃ³mico**: No requiere embeddings o bases de datos vectoriales
âœ… **Actualizable**: FÃ¡cil agregar/editar FAQs

## âš ï¸ Limitaciones

- BÃºsqueda bÃ¡sica (no semÃ¡ntica verdadera)
- Limitado a FAQs pre-definidas
- No escala bien con miles de documentos
- Requiere mantener keywords manualmente

## ğŸ“ Recursos

- [Vercel AI SDK](https://sdk.vercel.ai/docs)
- [Google Gemini API](https://ai.google.dev/)
- [RAG Explained](https://www.pinecone.io/learn/retrieval-augmented-generation/)
