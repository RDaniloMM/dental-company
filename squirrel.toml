[project]
domains = ["dental-company-tacna.com"]

[crawler]
max_pages = 100
coverage = "full"
delay_ms = 100
timeout_ms = 30000
user_agent = ""
follow_redirects = true
concurrency = 5
per_host_concurrency = 2
per_host_delay_ms = 200
# URLs de entrada para comenzar el crawl
include = []
exclude = [
  "/admin/*",
  "/api/*"
]
allow_query_params = []
drop_query_prefixes = [ "utm_", "gclid", "fbclid" ]
respect_robots = true
breadth_first = true
max_prefix_budget = 0.25

[rules]
enable = [ "*" ]
# Deshabilitamos reglas que generan falsos positivos:
# - leaked-secrets: detecta nombres de funciones minificadas como API keys
# - eeat/about-page: busca /about pero usamos /nosotros (español)
# - eeat/contact-page: busca /contact pero tenemos sección de contacto en landing
# - eeat/privacy-policy: busca /privacy-policy pero usamos /privacidad (español)
# - sitemap-valid: reporta error en sitemaps que no existen (sitemap_index.xml, etc)
disable = [ 
  "security/leaked-secrets",
  "eeat/about-page",
  "eeat/contact-page", 
  "eeat/privacy-policy",
  "crawl/sitemap-valid"
]

[external_links]
enabled = true
cache_ttl_days = 7
timeout_ms = 10000
concurrency = 5

[output]
format = "console"

[rule_options]
